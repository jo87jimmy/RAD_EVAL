import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.utils import make_grid, save_image
from torchvision import transforms as T
from PIL import Image
import numpy as np
from sklearn.metrics import roc_auc_score
from torch.utils.tensorboard import SummaryWriter
import random  # äº‚æ•¸æ§åˆ¶
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score
from loss import FocalLoss, SSIM
from model_unet import AnomalyDetectionModel
from data_loader import MVTecDRAEM_Test_Visual_Dataset
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import cv2

import os
import numpy as np  # ç”¨æ–¼æ•¸å€¼é‹ç®—


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# =======================
# Utilities
# =======================
def get_available_gpu():
    """è‡ªå‹•é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨ç‡æœ€ä½çš„GPU"""
    if not torch.cuda.is_available():
        return -1  # æ²’æœ‰GPUå¯ç”¨

    gpu_count = torch.cuda.device_count()
    if gpu_count == 0:
        return -1

    # æª¢æŸ¥æ¯å€‹GPUçš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
    gpu_memory = []
    for i in range(gpu_count):
        torch.cuda.set_device(i)
        memory_allocated = torch.cuda.memory_allocated(i)
        memory_reserved = torch.cuda.memory_reserved(i)
        gpu_memory.append((i, memory_allocated, memory_reserved))

    # é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨æœ€å°‘çš„GPU
    available_gpu = min(gpu_memory, key=lambda x: x[1])[0]
    return available_gpu


def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


def predict_anomaly(model, image_path, device):
    """
    å°å–®å¼µåœ–ç‰‡é€²è¡Œç•°å¸¸æª¢æ¸¬æ¨è«–ã€‚
    æ­¤å‡½æ•¸ä½¿ç”¨å›ºå®šçš„ã€ééš¨æ©Ÿçš„é è™•ç†æµç¨‹ã€‚

    Args:
        model (nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹
        image_path (str): è¼¸å…¥åœ–ç‰‡çš„è·¯å¾‘
        device (str): 'cuda' or 'cpu'

    Returns:
        tuple: (åŸå§‹åœ–åƒ, é‡å»ºåœ–åƒ, ç•°å¸¸é®ç½©) å‡ç‚º numpy array
    """
    # --- 1. å®šç¾©æ¨è«–æ™‚çš„åœ–åƒé è™•ç†æµç¨‹ ---
    # é€™è£¡åªåŒ…å«å¿…è¦çš„ã€ééš¨æ©Ÿçš„è½‰æ›ã€‚
    # ç¢ºä¿ Resize çš„å°ºå¯¸å’Œ Normalize çš„ mean/std èˆ‡æ‚¨è¨“ç·´æ™‚ä½¿ç”¨çš„å®Œå…¨ä¸€è‡´ï¼

    # å‡è¨­æ‚¨çš„æ¨¡å‹è¼¸å…¥å°ºå¯¸ç‚º 224x224
    TARGET_SIZE = (224, 224)

    # å‡è¨­æ‚¨è¨“ç·´æ™‚ä½¿ç”¨äº† ImageNet çš„å‡å€¼å’Œæ¨™æº–å·®é€²è¡Œæ¨™æº–åŒ–
    # å¦‚æœæ‚¨ä½¿ç”¨äº†ä¸åŒçš„å€¼ï¼Œè«‹å‹™å¿…åœ¨æ­¤è™•ä¿®æ”¹ï¼
    NORMALIZE_MEAN = [0.485, 0.456, 0.406]
    NORMALIZE_STD = [0.229, 0.224, 0.225]

    preprocess = transforms.Compose([
        transforms.Resize(TARGET_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),
    ])

    # --- 2. è¼‰å…¥ä¸¦é è™•ç†åœ–åƒ ---
    # ç¢ºä¿ä»¥ RGB æ¨¡å¼æ‰“é–‹ï¼Œèˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´
    image = Image.open(image_path).convert("RGB")
    # unsqueeze(0) æ˜¯ç‚ºäº†å¢åŠ ä¸€å€‹æ‰¹æ¬¡ç¶­åº¦ï¼Œå¾ [C, H, W] è®Šç‚º [1, C, H, W]
    image_tensor = preprocess(image).unsqueeze(0).to(device)

    # --- 3. åŸ·è¡Œå‰å‘å‚³æ’­ ---
    with torch.no_grad():
        recon_image_tensor, seg_map_logits = model(image_tensor,
                                                   return_feats=False)

    # --- 4. å¾Œè™•ç†è¼¸å‡º ---

    # a. è™•ç†åˆ†å‰²åœ– (Anomaly Mask)
    seg_map_probs = torch.softmax(seg_map_logits, dim=1)
    # æ²¿è‘—é€šé“ç¶­åº¦ (dim=1) æ‰¾åˆ°æœ€å¤§æ©Ÿç‡çš„ç´¢å¼• (0=æ­£å¸¸, 1=ç•°å¸¸)
    anomaly_mask_tensor = torch.argmax(seg_map_probs, dim=1)

    # b. å°‡ Tensor è½‰æ›ç‚ºå¯ç”¨æ–¼é¡¯ç¤ºçš„ NumPy Array

    # åŸå§‹åœ–åƒï¼Œèª¿æ•´åˆ°èˆ‡æ¨¡å‹è¼¸å…¥ç›¸åŒçš„å°ºå¯¸ä»¥ä¾¿æ¯”è¼ƒ
    original_image_np = np.array(image.resize(TARGET_SIZE))

    # åæ¨™æº–åŒ– (De-normalize) é‡å»ºåœ–åƒï¼Œä»¥ä¾¿èƒ½æ­£ç¢ºé¡¯ç¤º
    recon_image_np = recon_image_tensor.squeeze().cpu().numpy().transpose(
        1, 2, 0)
    mean = np.array(NORMALIZE_MEAN)
    std = np.array(NORMALIZE_STD)
    recon_image_np = std * recon_image_np + mean
    recon_image_np = np.clip(recon_image_np, 0, 1)  # å°‡æ•¸å€¼é™åˆ¶åœ¨ [0, 1] ç¯„åœå…§

    # å°‡é æ¸¬çš„é®ç½©è½‰æ›ç‚º numpy æ ¼å¼
    anomaly_mask_np = anomaly_mask_tensor.squeeze().cpu().numpy().astype(
        np.uint8)

    return original_image_np, recon_image_np, anomaly_mask_np


def run_inference(image_path, model, device, save_path, threshold=0.2):
    # ==================================================================
    # 4. é è™•ç†è¼¸å…¥åœ–åƒ
    # ==================================================================
    print(f"Step 4: Preprocessing the input image: {image_path}..."
          )  # é¡¯ç¤ºæ­£åœ¨è™•ç†çš„å½±åƒè·¯å¾‘

    preprocess = transforms.Compose([
        transforms.Resize([256, 256]),  # èª¿æ•´å½±åƒå¤§å°ç‚º 256x256
        transforms.ToTensor(),  # è½‰æ›ç‚º Tensor ä¸¦æ¨™æº–åŒ–åˆ° [0,1]
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],  # ä¾ç…§ ImageNet å‡å€¼åšæ­£è¦åŒ–
            std=[0.229, 0.224, 0.225])  # ä¾ç…§ ImageNet æ¨™æº–å·®åšæ­£è¦åŒ–
    ])

    image = Image.open(image_path).convert("RGB")  # è®€å–å½±åƒä¸¦è½‰æˆ RGB
    input_tensor = preprocess(image).unsqueeze(0).to(
        device)  # å¢åŠ  batch ç¶­åº¦ä¸¦æ¬åˆ° GPU/CPU

    # ==================================================================
    # 5. å‰å‘å‚³æ’­
    # ==================================================================
    print("Step 5: Performing inference...")  # é¡¯ç¤ºæ­£åœ¨åšæ¨è«–
    with torch.no_grad():  # é—œé–‰æ¢¯åº¦è¨ˆç®—ï¼Œç¯€çœè¨˜æ†¶é«”
        recon_image, seg_map = model(input_tensor,
                                     return_feats=False)  # æ¨¡å‹å‰å‘å‚³æ’­ï¼Œå–å¾—é‡å»ºå½±åƒèˆ‡åˆ†å‰²åœ°åœ–

    # ==================================================================
    # 6. å¾Œè™•ç†
    # ==================================================================
    print("Step 6: Post-processing the output...")  # é¡¯ç¤ºæ­£åœ¨åšå¾Œè™•ç†
    probabilities = torch.softmax(seg_map, dim=1)  # å°åˆ†å‰²åœ°åœ–åš softmaxï¼Œå–å¾—æ¯å€‹é¡åˆ¥æ©Ÿç‡
    anomaly_map = probabilities[:, 1, :, :]  # å–é€šé“1çš„ç•°å¸¸æ©Ÿç‡ (å‡è¨­é€šé“0æ˜¯æ­£å¸¸ï¼Œé€šé“1æ˜¯ç•°å¸¸)

    image_anomaly_score = torch.max(anomaly_map).item()  # å–æ•´å¼µå½±åƒæœ€å¤§ç•°å¸¸æ©Ÿç‡ä½œç‚ºå½±åƒç´šåˆ†æ•¸
    print(f"Image-level anomaly score: {image_anomaly_score:.4f}")  # é¡¯ç¤ºå½±åƒç•°å¸¸åˆ†æ•¸

    # äºŒå€¼åŒ– mask
    binary_mask = (anomaly_map > threshold).squeeze().cpu().numpy().astype(
        np.uint8) * 255  # å°‡ç•°å¸¸æ©Ÿç‡å¤§æ–¼é–¾å€¼çš„å€åŸŸè¨­ç‚º 255ï¼Œå½¢æˆäºŒå€¼åŒ–é®ç½©

    # Normalize anomaly map (0~255)
    anomaly_map_np = anomaly_map.squeeze().cpu().numpy()  # å°‡ç•°å¸¸æ©Ÿç‡è½‰æˆ numpy
    anomaly_map_norm = (anomaly_map_np - anomaly_map_np.min()) / (
        anomaly_map_np.max() - anomaly_map_np.min() + 1e-8)  # å°‡ç•°å¸¸æ©Ÿç‡æ­£è¦åŒ–åˆ° 0~1
    anomaly_map_visual = (anomaly_map_norm * 255).astype(
        np.uint8)  # å°‡æ­£è¦åŒ–çµæœè½‰æˆ 0~255 çš„å½±åƒ

    # Heatmap (å½©è‰²)
    heatmap = cv2.applyColorMap(anomaly_map_visual,
                                cv2.COLORMAP_JET)  # å°‡ç•°å¸¸åœ°åœ–è½‰æˆå½©è‰²ç†±åŠ›åœ–

    print("Seg_map logits min/max:",
          seg_map.min().item(),
          seg_map.max().item())  # é¡¯ç¤ºåˆ†å‰²åœ°åœ–åŸå§‹ logits çš„æœ€å°æœ€å¤§å€¼
    print("Anomaly_map min/max:",
          anomaly_map.min().item(),
          anomaly_map.max().item())  # é¡¯ç¤ºç•°å¸¸åœ°åœ–æ©Ÿç‡çš„æœ€å°æœ€å¤§å€¼

    # ==================================================================
    # 7. å„²å­˜çµæœ
    # ==================================================================
    anomaly_map_path = f"{save_path}_anomaly_map.png"  # è¨­å®šç•°å¸¸åœ–å„²å­˜è·¯å¾‘
    binary_mask_path = f"{save_path}_binary_mask.png"  # è¨­å®šäºŒå€¼åŒ–é®ç½©å„²å­˜è·¯å¾‘
    heatmap_path = f"{save_path}_heatmap.png"  # è¨­å®šå½©è‰²ç†±åŠ›åœ–å„²å­˜è·¯å¾‘

    Image.fromarray(anomaly_map_visual).save(anomaly_map_path)  # å„²å­˜ç°éšç•°å¸¸åœ–
    Image.fromarray(binary_mask).save(binary_mask_path)  # å„²å­˜äºŒå€¼é®ç½©
    cv2.imwrite(heatmap_path, heatmap)  # å„²å­˜å½©è‰²ç†±åŠ›åœ–

    print(f"âœ… å„²å­˜å®Œæˆï¼š{anomaly_map_path}, {binary_mask_path}, {heatmap_path}"
          )  # é¡¯ç¤ºå„²å­˜å®Œæˆè¨Šæ¯

    return anomaly_map_visual, binary_mask  # å›å‚³ç•°å¸¸åœ–èˆ‡äºŒå€¼é®ç½©


def visualize_and_save(original_img, recon_img, anomaly_map, binary_mask,
                       save_path_base):
    """
    å°‡æ¨è«–çµæœå¯è¦–åŒ–ä¸¦å„²å­˜æˆåœ–ç‰‡ã€‚

    Args:
        original_img (np.ndarray): åŸå§‹è¼¸å…¥å½±åƒ (H, W, C)ã€‚
        recon_img (np.ndarray): é‡å»ºå¾Œçš„å½±åƒ (H, W, C)ã€‚
        anomaly_map (np.ndarray): ç•°å¸¸åˆ†æ•¸åœ– (H, W)ï¼Œå€¼åŸŸ [0, 1]ã€‚
        binary_mask (np.ndarray): äºŒå€¼åŒ–çš„ç•°å¸¸é®ç½© (H, W)ï¼Œå€¼ç‚º 0 æˆ– 255ã€‚
        save_path_base (str): å„²å­˜æª”æ¡ˆçš„åŸºç¤è·¯å¾‘èˆ‡æª”å (ä¸å«å‰¯æª”å)ã€‚
    """
    # ç¢ºä¿å„²å­˜ç›®éŒ„å­˜åœ¨
    save_dir = os.path.dirname(save_path_base)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir, exist_ok=True)

    # å°‡ anomaly_map è½‰æ›ç‚ºç†±åŠ›åœ–
    # å°‡ç°éšçš„ anomaly_map (0-1) è½‰ç‚º 8-bit æ•´æ•¸ (0-255)
    heatmap_gray = (anomaly_map * 255).astype(np.uint8)
    heatmap_color = cv2.applyColorMap(heatmap_gray, cv2.COLORMAP_JET)

    # å°‡ç†±åŠ›åœ–ç–ŠåŠ åˆ°åŸå§‹å½±åƒä¸Š
    overlay = cv2.addWeighted(original_img, 0.6, heatmap_color, 0.4, 0)

    # å°‡äºŒå€¼åŒ–é®ç½©è½‰ç‚ºä¸‰é€šé“ï¼Œæ–¹ä¾¿åˆä½µ
    binary_mask_color = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)

    # å°‡å››å¼µåœ–æ‹¼æ¥æˆä¸€å¼µå¤§åœ– (åŸå§‹åœ– | é‡å»ºåœ– | ç†±åŠ›åœ– | äºŒå€¼åœ–)
    combined_img = np.hstack(
        [original_img, recon_img, overlay, binary_mask_color])

    # å„²å­˜åˆä½µå¾Œçš„å½±åƒ
    cv2.imwrite(f"{save_path_base}_results.png", combined_img)
    print(f"âœ… çµæœå·²å„²å­˜è‡³: {save_path_base}_results.png")


def run_inference(img_path, model, device, save_path_base):
    """
    å°å–®å¼µå½±åƒåŸ·è¡Œç•°å¸¸æª¢æ¸¬æ¨è«–ã€‚

    Args:
        img_path (str): è¼¸å…¥å½±åƒçš„è·¯å¾‘ã€‚
        model (nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹ã€‚
        device (str): 'cuda' æˆ– 'cpu'ã€‚
        save_path_base (str): å„²å­˜çµæœçš„åŸºç¤è·¯å¾‘èˆ‡æª”åã€‚

    Returns:
        tuple: (anomaly_map, binary_mask)
    """
    # --- 1. å½±åƒé è™•ç† ---
    # å®šç¾©èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„è½‰æ›æµç¨‹
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])

    # è®€å–å½±åƒä¸¦è½‰æ›
    original_img_cv = cv2.imread(img_path)
    if original_img_cv is None:
        print(f"âŒ éŒ¯èª¤: ç„¡æ³•è®€å–å½±åƒ {img_path}")
        return None, None
    original_img_rgb = cv2.cvtColor(original_img_cv,
                                    cv2.COLOR_BGR2RGB)  # è½‰ç‚º RGB
    img_tensor = transform(original_img_rgb).unsqueeze(0).to(device)

    # --- 2. åŸ·è¡Œæ¨¡å‹æ¨è«– ---
    with torch.no_grad():
        recon_image, seg_map = model(img_tensor)

    # --- 3. çµæœå¾Œè™•ç† ---
    # å°‡è¼¸å‡ºçš„ logit è½‰æ›ç‚ºæ©Ÿç‡åˆ†ä½ˆ
    seg_map_softmax = torch.softmax(seg_map, dim=1)
    # å–å‡º "ç•°å¸¸" é¡åˆ¥çš„æ©Ÿç‡åœ– (å‡è¨­é¡åˆ¥ 1 æ˜¯ç•°å¸¸)
    anomaly_map_tensor = seg_map_softmax[:, 1, :, :]

    # å°‡ Tensor è½‰ç‚º NumPy array ä»¥ä¾¿å¾ŒçºŒè™•ç†
    # .squeeze() å»æ‰æ‰¹æ¬¡ç¶­åº¦, .cpu() ç§»è‡³ CPU, .numpy() è½‰æ›æ ¼å¼
    anomaly_map = anomaly_map_tensor.squeeze().cpu().numpy()
    recon_image_np = recon_image.squeeze().cpu().permute(1, 2, 0).numpy()
    # å°‡é‡å»ºåœ–çš„åƒç´ å€¼å¾ [0, 1] è½‰å› [0, 255]
    recon_image_np = (recon_image_np * 255).astype(np.uint8)
    recon_image_bgr = cv2.cvtColor(recon_image_np, cv2.COLOR_RGB2BGR)

    # --- 4. ç”¢ç”ŸäºŒå€¼åŒ–é®ç½© ---
    # è¨­å®šä¸€å€‹é–¾å€¼ï¼Œå°‡ç•°å¸¸æ©Ÿç‡å¤§æ–¼è©²å€¼çš„åƒç´ æ¨™è¨˜ç‚º 1 (ç•°å¸¸)
    threshold = 0.9
    binary_mask = (anomaly_map > threshold).astype(
        np.uint8) * 255  # è½‰ç‚º 0 æˆ– 255

    # --- 5. å¯è¦–åŒ–ä¸¦å„²å­˜ ---
    # ç¢ºä¿åŸå§‹å½±åƒå°ºå¯¸ç‚º 256x256ï¼Œä»¥ä¾¿æ‹¼æ¥
    original_img_resized = cv2.resize(original_img_cv, (256, 256))
    #åŸå§‹åœ–ã€é‡å»ºåœ–ã€ç†±åŠ›åœ–ã€äºŒå€¼åœ–
    visualize_and_save(original_img_resized, recon_image_bgr, anomaly_map,
                       binary_mask, save_path_base)

    return anomaly_map, binary_mask


#å®Œæˆç‰ˆ!
# def run_inference(image_path, model, device, save_path):
#     # ==================================================================
#     # 4. é è™•ç†è¼¸å…¥åœ–åƒ
#     #    - é è™•ç†æ­¥é©Ÿå¿…é ˆèˆ‡è¨“ç·´æ™‚çš„é©—è­‰é›†/æ¸¬è©¦é›†å®Œå…¨ç›¸åŒï¼
#     # ==================================================================
#     print(f"Step 4: Preprocessing the input image: {image_path}...")
#     # é€™è£¡çš„ resize_shape å’Œ normalize åƒæ•¸æ‡‰èˆ‡è¨“ç·´æ™‚ä¸€è‡´
#     preprocess = transforms.Compose([
#         transforms.Resize([256, 256]),
#         transforms.ToTensor(),
#         transforms.Normalize(mean=[0.485, 0.456, 0.406],
#                              std=[0.229, 0.224,
#                                   0.225])  # å‡è¨­ä½¿ç”¨ ImageNet çš„å‡å€¼å’Œæ¨™æº–å·®
#     ])

#     image = Image.open(image_path).convert("RGB")
#     input_tensor = preprocess(image).unsqueeze(0).to(
#         device)  # unsqueeze(0) æ˜¯ç‚ºäº†å¢åŠ  batch ç¶­åº¦

#     # ==================================================================
#     # 5. åŸ·è¡Œå‰å‘å‚³æ’­ (åœ¨ torch.no_grad() ç’°å¢ƒä¸‹)
#     # ==================================================================
#     print("Step 5: Performing inference...")
#     with torch.no_grad():
#         # æ¨ç†æ™‚ï¼Œæˆ‘å€‘åªéœ€è¦åˆ†å‰²åœ–ï¼Œæ‰€ä»¥ return_feats=False
#         # å­¸ç”Ÿæ¨¡å‹æœƒåŒæ™‚è¼¸å‡ºé‡å»ºåœ–å’Œåˆ†å‰²åœ–
#         recon_image, seg_map = model(input_tensor, return_feats=False)

#     # recon_image = recon_image.squeeze().cpu().numpy().transpose(1, 2, 0)
#     # recon_image = (recon_image * 255).astype(np.uint8)
#     # Image.fromarray(recon_image).save(f"{save_path}_recon.png")
#     # ==================================================================
#     # 6. å¾Œè™•ç†è¼¸å‡ºçµæœ
#     # ==================================================================
#     print("Step 6: Post-processing the output...")
#     # seg_map çš„å½¢ç‹€æ˜¯ [batch_size, num_classes, H, W]ï¼Œä¾‹å¦‚ [1, 2, 256, 256]
#     # æˆ‘å€‘éœ€è¦çš„æ˜¯ä»£è¡¨ "ç•°å¸¸" çš„é‚£å€‹é€šé“çš„æ©Ÿç‡

#     # ä½¿ç”¨ softmax å°‡ logits è½‰æ›ç‚ºæ©Ÿç‡
#     probabilities = torch.softmax(seg_map, dim=1)

#     # æå–ç•°å¸¸é¡åˆ¥çš„æ©Ÿç‡åœ– (å‡è¨­é€šé“ 1 ä»£è¡¨ç•°å¸¸, é€šé“ 0 ä»£è¡¨æ­£å¸¸)
#     anomaly_map = probabilities[:, 1, :, :]

#     # ç²å–æ•´å¼µåœ–ç‰‡çš„ç•°å¸¸åˆ†æ•¸ (å¯ä»¥æ˜¯æœ€å¤§å€¼æˆ–å¹³å‡å€¼)
#     image_anomaly_score = torch.max(anomaly_map).item()
#     print(f"Image-level anomaly score: {image_anomaly_score:.4f}")

#     # å¯ä»¥è¨­å®šä¸€å€‹é–¾å€¼ä¾†å¾—åˆ°äºŒå€¼åŒ–çš„ç•°å¸¸é®ç½©
#     threshold = 0.5
#     binary_mask = (anomaly_map
#                    > threshold).squeeze().cpu().numpy().astype(np.uint8)

#     # å°‡ç•°å¸¸åˆ†æ•¸åœ–è½‰æ›ç‚ºå¯è¦–åŒ–çš„ç°åº¦åœ–
#     anomaly_map_visual = (anomaly_map.squeeze().cpu().numpy() * 255).astype(
#         np.uint8)
#     print("Seg_map logits min/max:",
#           seg_map.min().item(),
#           seg_map.max().item())
#     print("Anomaly_map min/max:",
#           anomaly_map.min().item(),
#           anomaly_map.max().item())
#     return anomaly_map_visual, binary_mask


# =======================
# Main Pipeline
# =======================
def main(obj_names, args):
    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # å»ºç«‹ä¸»å­˜æª”è³‡æ–™å¤¾
    save_root = "./save_files"
    if not os.path.exists(save_root):
        os.makedirs(save_root)
    print("ğŸ”„ é–‹å§‹æ¸¬è©¦ï¼Œå…±æœ‰ç‰©ä»¶é¡åˆ¥:", len(obj_names))
    for obj_name in obj_names:
        print(f"â–¶ï¸æ¸¬è©¦ç‰©ä»¶é¡åˆ¥: {obj_name}")
        # Load
        IMG_CHANNELS = 3
        SEG_CLASSES = 2
        student_model = AnomalyDetectionModel(
            recon_in=IMG_CHANNELS,
            recon_out=IMG_CHANNELS,
            recon_base=64,  # <-- ä½¿ç”¨å°å‹æ¨¡å‹çš„åƒæ•¸
            disc_in=IMG_CHANNELS * 2,
            disc_out=SEG_CLASSES,
            disc_base=64  # <-- ä½¿ç”¨å°å‹æ¨¡å‹çš„åƒæ•¸
        ).to(device)

        # è¼‰å…¥è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹æ¬Šé‡
        model_weights_path = './student_model_checkpoints/bottle.pckl'  # â¬…ï¸ æˆ‘çš„çš„æ¬Šé‡è·¯å¾‘
        student_model.load_state_dict(
            torch.load(model_weights_path, map_location=device))

        # --- 2. è¨­å®šç‚ºè©•ä¼°æ¨¡å¼ ---
        student_model.eval()

        test_path = './mvtec/' + obj_name + '/test'  # æ¸¬è©¦è³‡æ–™è·¯å¾‘
        items = ['good', 'broken_large', 'broken_small',
                 'contamination']  # æ¸¬è©¦è³‡æ–™æ¨™ç±¤
        print(f"ğŸ” æ¸¬è©¦è³‡æ–™å¤¾ï¼š{test_path}ï¼Œå…± {len(items)} é¡åˆ¥")

        # ä¾é¡åˆ¥é€å¼µè®€å–å½±åƒä¸¦åŸ·è¡Œæ¨è«–
        for item in items:
            item_path = os.path.join(test_path, item)
            # å»ºç«‹è©²é¡åˆ¥çš„è¼¸å‡ºè³‡æ–™å¤¾
            output_dir = os.path.join(save_root, obj_name, item)
            os.makedirs(output_dir, exist_ok=True)  # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨

            if not os.path.exists(item_path):
                print(f"âš ï¸ è­¦å‘Š: è·¯å¾‘ä¸å­˜åœ¨ {item_path}ï¼Œè·³éã€‚")
                continue

            img_files = [
                f for f in os.listdir(item_path)
                if f.endswith('.png') or f.endswith('.jpg')
            ]

            print(f"\nğŸ“‚ é¡åˆ¥ï¼š{item}ï¼Œå…± {len(img_files)} å¼µå½±åƒ")

            for img_name in img_files:
                img_path = os.path.join(item_path, img_name)
                print(f"ğŸ–¼ï¸ è™•ç†å½±åƒï¼š{img_path}")

                # å»æ‰å‰¯æª”åï¼Œåªå–æª”åä¸»é«”
                base_name, _ = os.path.splitext(img_name)
                # è¨­å®šå„²å­˜è·¯å¾‘
                save_path_base = os.path.join(output_dir, base_name)

                # --- åŸ·è¡Œæ¨ç† ---
                anomaly_map, binary_mask = run_inference(
                    img_path, student_model, device, save_path_base)
        print(f"\nâœ… ç‰©ä»¶é¡åˆ¥ {obj_name} æ¸¬è©¦å®Œæˆï¼")
    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å·²å®Œæˆï¼")
    # original, reconstruction, anomaly_mask = predict_anomaly(
    #     student_model, img_path, device)

    # # å°‡ numpy array è½‰æ›ç‚º PIL Image
    # anomaly_map_img = Image.fromarray(anomaly_map)
    # binary_mask_img = Image.fromarray(binary_mask *
    #                                   255)  # ä¹˜ä»¥ 255 ä½¿å…¶å¯è¦–åŒ–

    # # å„²å­˜åœ–ç‰‡ï¼ŒåŠ ä¸ŠåŸæª”åæ–¹ä¾¿å€åˆ†
    # # åŸå§‹è¼¸å…¥è·¯å¾‘
    # orig_img_path = os.path.join(item_path, img_name)
    # save_img_path = os.path.join(save_root, f"{base_name}_img.png")
    # anomaly_map_path = os.path.join(
    #     save_root, f"{base_name}_anomaly_map.png")  #ç•°å¸¸åœ–
    # binary_mask_path = os.path.join(
    #     save_root, f"{base_name}_binary_mask.png")  #ç•°å¸¸é®ç½©
    # Image.open(orig_img_path).save(
    #     save_img_path)  # é–‹å•ŸåŸå§‹åœ–ç‰‡ä¸¦å¦å­˜åˆ° save_root
    # anomaly_map_img.save(anomaly_map_path)
    # binary_mask_img.save(binary_mask_path)

    # print(f"âœ… å„²å­˜å®Œæˆï¼š{anomaly_map_path}, {binary_mask_path}")


# =======================
# Run pipeline
# =======================
if __name__ == "__main__":
    """
    --gpu_id -2ï¼šè‡ªå‹•é¸æ“‡æœ€ä½³GPU
    --gpu_id -1ï¼šå¼·åˆ¶ä½¿ç”¨CPU
    --gpu_id  0ï¼šä½¿ç”¨GPU 0ï¼ˆåŸæœ‰è¡Œç‚ºï¼‰
    """

    parser = argparse.ArgumentParser()
    parser.add_argument('--obj_id', action='store', type=int, required=True)
    parser.add_argument('--gpu_id',
                        action='store',
                        type=int,
                        default=-2,
                        required=False,
                        help='GPU ID (-2: auto-select, -1: CPU)')
    args = parser.parse_args()

    # è‡ªå‹•é¸æ“‡GPU
    if args.gpu_id == -2:  # è‡ªå‹•é¸æ“‡æ¨¡å¼
        args.gpu_id = get_available_gpu()
        print(f"è‡ªå‹•é¸æ“‡ GPU: {args.gpu_id}")

    obj_batch = [['capsule'], ['bottle'], ['carpet'], ['leather'], ['pill'],
                 ['transistor'], ['tile'], ['cable'], ['zipper'],
                 ['toothbrush'], ['metal_nut'], ['hazelnut'], ['screw'],
                 ['grid'], ['wood']]

    if int(args.obj_id) == -1:
        obj_list = [
            'capsule', 'bottle', 'carpet', 'leather', 'pill', 'transistor',
            'tile', 'cable', 'zipper', 'toothbrush', 'metal_nut', 'hazelnut',
            'screw', 'grid', 'wood'
        ]
        picked_classes = obj_list
    else:
        picked_classes = obj_batch[int(args.obj_id)]

    # æ ¹æ“šé¸æ“‡çš„GPUåŸ·è¡Œ
    if args.gpu_id == -1:
        # ä½¿ç”¨CPU
        main(picked_classes, args)
    else:
        # ä½¿ç”¨GPU
        with torch.cuda.device(args.gpu_id):
            main(picked_classes, args)
